# 05. A/B 테스트 분석 (고급)

## 학습 목표

이 모듈을 완료하면 다음을 할 수 있습니다:

1. **A/B 테스트 설계** 원칙을 이해하고 적용할 수 있다
2. SQL로 **실험 데이터를 정확하게 집계**할 수 있다
3. **통계적 유의성**을 계산하고 해석할 수 있다
4. **샘플 사이즈**를 계산하고 실험 기간을 산정할 수 있다
5. **세그먼트별 분석**으로 숨겨진 인사이트를 발견할 수 있다
6. 실험 결과로 **비즈니스 의사결정**을 내릴 수 있다

---

## 핵심 개념

### A/B 테스트란?

> 두 가지 버전(A: 대조군, B: 실험군)을 무작위로 노출하여
> 어떤 버전이 더 좋은 성과를 내는지 **데이터로 검증**하는 방법

### 왜 중요한가?

1. **직관이 아닌 데이터 기반 의사결정**
2. **변화의 효과를 정량적으로 측정**
3. **리스크 최소화**: 전체 적용 전 일부로 테스트
4. **지속적 개선 문화** 구축

---

## 실무 A/B 테스트 프로세스

```
1. 가설 수립
   └─ "버튼 색상을 파란색으로 바꾸면 전환율이 10% 증가할 것이다"

2. 실험 설계
   ├─ 성공 지표 정의 (Primary Metric)
   ├─ 가드레일 지표 정의 (Guardrail Metrics)
   ├─ 샘플 사이즈 계산
   └─ 실험 기간 산정

3. 실험 실행
   ├─ 무작위 배정 (Randomization)
   ├─ 트래픽 분할 (50:50 또는 기타)
   └─ 데이터 수집

4. 결과 분석
   ├─ 전환율 계산
   ├─ 통계적 유의성 검정
   ├─ 신뢰구간 계산
   └─ 세그먼트별 분석

5. 의사결정
   ├─ 유의미 + 긍정적 → 적용
   ├─ 유의미 + 부정적 → 기각
   └─ 비유의미 → 실험 연장 또는 종료
```

---

## 핵심 통계 개념

### 1. 가설 검정

| 개념 | 설명 |
|------|------|
| **귀무가설 (H₀)** | "차이가 없다" - Control과 Treatment가 동일 |
| **대립가설 (H₁)** | "차이가 있다" - Treatment가 더 낫다 (또는 다르다) |
| **유의수준 (α)** | 귀무가설이 참인데 기각할 확률 (보통 0.05) |
| **검정력 (1-β)** | 대립가설이 참일 때 이를 탐지할 확률 (보통 0.80) |

### 2. p-value 해석

```
p-value = 귀무가설이 참일 때, 관측된 결과(또는 더 극단적인 결과)가 나올 확률

p < 0.05  → 통계적으로 유의 (95% 신뢰수준)
p < 0.01  → 매우 유의 (99% 신뢰수준)
p >= 0.05 → 유의하지 않음 (우연일 수 있음)
```

**주의사항:**
- p-value는 효과의 크기를 말해주지 않음
- 표본이 크면 작은 차이도 유의할 수 있음
- 실무적 유의성(Practical Significance)도 함께 고려해야 함

### 3. Z-검정 (Two-Proportion Z-Test)

전환율 비교를 위한 공식:

```
Z = (p₂ - p₁) / SE

SE = √(p_pool × (1 - p_pool) × (1/n₁ + 1/n₂))

p_pool = (x₁ + x₂) / (n₁ + n₂)

여기서:
- p₁, p₂: 각 그룹의 전환율
- n₁, n₂: 각 그룹의 샘플 수
- x₁, x₂: 각 그룹의 전환 수
```

### 4. 필요 샘플 사이즈 계산

```
n = 2 × ((Z_α + Z_β)² × p × (1-p)) / (MDE)²

여기서:
- Z_α = 1.96 (95% 신뢰수준)
- Z_β = 0.84 (80% 검정력)
- p = 기준 전환율
- MDE = 최소 감지 효과 (Minimum Detectable Effect)
```

예시: 기준 전환율 5%, MDE 20% (상대적)
```
MDE (절대) = 5% × 20% = 1%
n = 2 × ((1.96 + 0.84)² × 0.05 × 0.95) / (0.01)²
n ≈ 7,450명 (그룹당)
```

---

## 학습 문제 (총 10문제)

### Level 1: 기본 분석

| # | 문제 | 핵심 SQL | 난이도 |
|---|------|----------|--------|
| 1 | 그룹별 전환율 계산 | GROUP BY, AVG | ⭐ |
| 2 | 전환율 차이 (Uplift) 계산 | CTE, 서브쿼리 | ⭐ |
| 3 | 일별 전환율 추이 분석 | GROUP BY date | ⭐⭐ |

### Level 2: 통계 분석

| # | 문제 | 핵심 SQL | 난이도 |
|---|------|----------|--------|
| 4 | Pooled 전환율 계산 | 집계 함수 | ⭐⭐ |
| 5 | Standard Error 계산 | SQRT, 수학 연산 | ⭐⭐ |
| 6 | Z-score 계산 | CTE 체이닝 | ⭐⭐⭐ |

### Level 3: 고급 분석

| # | 문제 | 핵심 SQL | 난이도 |
|---|------|----------|--------|
| 7 | 세그먼트별 실험 효과 분석 | GROUP BY segment | ⭐⭐⭐ |
| 8 | 시간대별 전환율 패턴 | strftime, CASE | ⭐⭐⭐ |
| 9 | 신규/기존 고객별 효과 | JOIN, CASE | ⭐⭐⭐ |
| 10 | 종합 실험 리포트 생성 | 복합 CTE | ⭐⭐⭐⭐ |

---

## 테이블 구조

### ab_tests 테이블

```sql
CREATE TABLE ab_tests (
    test_id TEXT,           -- 실험 ID (예: 'checkout_button_v2')
    user_id INTEGER,        -- 유저 ID
    variant TEXT,           -- 'control' 또는 'treatment'
    converted INTEGER,      -- 전환 여부 (0 또는 1)
    conversion_value REAL,  -- 전환 금액
    device TEXT,            -- 디바이스 유형
    user_segment TEXT,      -- 유저 세그먼트 (new/returning)
    created_at TEXT         -- 실험 노출 시점
);
```

### 예시 데이터

| test_id | user_id | variant | converted | device | user_segment |
|---------|---------|---------|-----------|--------|--------------|
| checkout_v2 | 1001 | control | 0 | mobile | new |
| checkout_v2 | 1002 | treatment | 1 | desktop | returning |
| checkout_v2 | 1003 | control | 1 | mobile | returning |

---

## 면접 대비 포인트

### 자주 묻는 질문

**Q1: "A/B 테스트를 어떻게 설계하셨나요?"**

> "먼저 가설을 명확히 수립합니다. 예를 들어 '결제 버튼을 녹색으로 바꾸면 전환율이 10% 증가할 것이다'라는 가설을 세웁니다.
>
> 다음으로 필요한 샘플 사이즈를 계산합니다. 기준 전환율 3%, MDE 15%, 유의수준 5%, 검정력 80% 기준으로 그룹당 약 12,000명이 필요했습니다.
>
> 무작위 배정을 위해 user_id를 해싱하여 50:50으로 분할했고, 2주간 실험을 진행했습니다."

**Q2: "통계적으로 유의하지 않으면 어떻게 하시겠습니까?"**

> "먼저 샘플 사이즈가 충분한지 확인합니다. 부족하다면 실험 기간을 연장합니다.
>
> 충분한 샘플에도 유의하지 않다면, 두 버전 간 실제 차이가 없다는 것을 의미합니다. 이 경우 다른 가설을 테스트하거나, 더 큰 변화를 시도해볼 수 있습니다.
>
> 중요한 것은 '유의하지 않음'도 의미있는 결과라는 점입니다. 불필요한 변경을 막아주기 때문입니다."

**Q3: "p-value만으로 의사결정하면 안 되는 이유는?"**

> "p-value는 효과의 크기를 말해주지 않습니다. 샘플이 충분히 크면 0.01%의 차이도 유의할 수 있습니다.
>
> 따라서 신뢰구간을 함께 확인하고, 실무적 유의성(Practical Significance)을 고려해야 합니다.
>
> 예를 들어 전환율이 0.1%p 증가하고 p-value가 0.01이라도, 그 효과가 개발 비용 대비 가치가 있는지 판단해야 합니다."

**Q4: "Simpson's Paradox를 경험해보셨나요?"**

> "네, 전체 데이터에서는 Treatment가 더 좋아 보였지만, 세그먼트별로 분석하니 모든 세그먼트에서 Control이 더 좋은 경우가 있었습니다.
>
> 이는 Treatment 그룹에 전환율이 높은 세그먼트(예: 기존 고객)가 더 많이 배정되어 생긴 현상이었습니다.
>
> 이후로는 항상 주요 세그먼트별 분석을 함께 진행하고, 그룹 간 특성이 균형있게 배정되었는지 확인합니다."

---

## 실무 체크리스트

### 실험 전

- [ ] 가설이 명확하고 검증 가능한가?
- [ ] Primary Metric이 정의되었는가?
- [ ] Guardrail Metrics가 정의되었는가?
- [ ] 필요 샘플 사이즈를 계산했는가?
- [ ] 예상 실험 기간을 산정했는가?
- [ ] 무작위 배정이 올바르게 구현되었는가?

### 실험 중

- [ ] 데이터가 정상적으로 수집되고 있는가?
- [ ] 그룹 간 샘플 수가 균형있는가?
- [ ] 이상치나 데이터 오류가 없는가?
- [ ] 외부 요인(시즌, 이벤트)이 영향을 주고 있지 않은가?

### 실험 후

- [ ] 통계적 유의성을 확인했는가?
- [ ] 신뢰구간을 계산했는가?
- [ ] 세그먼트별 분석을 수행했는가?
- [ ] Guardrail Metrics에 부정적 영향이 없는가?
- [ ] 결과가 비즈니스적으로 의미있는가?

---

## 추가 학습 자료

### 필독 자료

1. **Trustworthy Online Controlled Experiments** (Ron Kohavi)
   - A/B 테스트의 바이블로 불리는 책

2. **Statistical Methods in Online A/B Testing** (Georgi Georgiev)
   - 통계적 방법론 심화

### 실무 블로그

- Airbnb Engineering Blog - Experimentation
- Netflix Tech Blog - A/B Testing
- Booking.com - 150 Successful Experiments

---

## 주의사항

### 흔한 실수

1. **Peeking Problem**: 실험 도중 결과를 보고 조기 종료
2. **Multiple Testing**: 여러 지표를 테스트하면서 보정 없이 해석
3. **Novelty Effect**: 새로움에 대한 일시적 반응을 진짜 효과로 오해
4. **Selection Bias**: 무작위 배정이 제대로 안 된 경우
5. **Survivorship Bias**: 이탈한 유저를 분석에서 제외

### 윤리적 고려

- 사용자에게 해가 되는 실험은 하지 않기
- 민감한 기능(결제, 보안)은 신중하게 테스트
- 실험 결과를 투명하게 공유
